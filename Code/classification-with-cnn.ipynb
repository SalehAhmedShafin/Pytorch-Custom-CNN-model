{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport random\nimport shutil\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader\nfrom torchvision import transforms\nfrom torchvision.datasets import ImageFolder\nfrom PIL import ImageOps\n\ntorch.manual_seed(100)","metadata":{"id":"4pN935wKJgKN","outputId":"9f13346e-3036-4bdf-d796-5c9f87142dff","execution":{"iopub.status.busy":"2023-07-31T19:55:12.463076Z","iopub.execute_input":"2023-07-31T19:55:12.463567Z","iopub.status.idle":"2023-07-31T19:55:12.472284Z","shell.execute_reply.started":"2023-07-31T19:55:12.463523Z","shell.execute_reply":"2023-07-31T19:55:12.471325Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"<torch._C.Generator at 0x7f8f59354630>"},"metadata":{}}]},{"cell_type":"code","source":"old_names = [\"NORMAL\", \"COVID\", \"PNEUMONIA\"]\nnew_names = [\"0\", \"1\", \"2\"]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_path = 'C:\\\\Users\\\\Asus\\\\Downloads\\\\SoftLab\\\\Assignment1\\\\Dataset\\\\'\ntrain_path =   'C:\\\\Users\\\\Asus\\\\Downloads\\\\SoftLab\\\\Assignment1\\\\Final_Dataset\\\\train\\\\'\nval_path =     'C:\\\\Users\\\\Asus\\\\Downloads\\\\SoftLab\\\\Assignment1\\\\Final_Dataset\\\\val\\\\'\ntest_path =    'C:\\\\Users\\\\Asus\\\\Downloads\\\\SoftLab\\\\Assignment1\\\\Final_Dataset\\\\test\\\\'","metadata":{"id":"s5MM_yA9ji4l","execution":{"iopub.status.busy":"2023-07-31T19:55:12.474320Z","iopub.execute_input":"2023-07-31T19:55:12.474747Z","iopub.status.idle":"2023-07-31T19:55:12.484767Z","shell.execute_reply.started":"2023-07-31T19:55:12.474711Z","shell.execute_reply":"2023-07-31T19:55:12.483573Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"for old_name, new_name in zip(old_names, new_names):\n    old_folder_path = os.path.join(dataset_path, old_name)\n    new_folder_path = os.path.join(dataset_path, new_name)\n    os.rename(old_folder_path, new_folder_path)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classes = ['0' ,'1' ,'2']\nbatch_size = 32\nnum_iters=3000","metadata":{"execution":{"iopub.status.busy":"2023-07-31T19:55:12.485913Z","iopub.execute_input":"2023-07-31T19:55:12.488062Z","iopub.status.idle":"2023-07-31T19:55:12.493559Z","shell.execute_reply.started":"2023-07-31T19:55:12.488037Z","shell.execute_reply":"2023-07-31T19:55:12.492623Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"os.makedirs(train_path, exist_ok=True)\nos.makedirs(val_path, exist_ok=True)\nos.makedirs(test_path, exist_ok=True)\n\ntrain_ratio = 0.7\nval_ratio = 0.15\ntest_ratio = 0.15","metadata":{"id":"zNxQozaWj936","execution":{"iopub.status.busy":"2023-07-31T19:55:12.496764Z","iopub.execute_input":"2023-07-31T19:55:12.497292Z","iopub.status.idle":"2023-07-31T19:55:12.503936Z","shell.execute_reply.started":"2023-07-31T19:55:12.497261Z","shell.execute_reply":"2023-07-31T19:55:12.502998Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"for class_name in classes:\n    print(class_name)\n    class_folder_path = os.path.join(dataset_path, class_name)\n    images = os.listdir(class_folder_path)\n    random.shuffle(images)\n\n    train_split = int(len(images) * train_ratio)\n    val_split = int(len(images) * (train_ratio + val_ratio))\n\n    train_images = images[:train_split]\n    val_images = images[train_split:val_split]\n    test_images = images[val_split:]\n\n    for img_name in train_images:\n        src = os.path.join(class_folder_path, img_name)\n        dst = os.path.join(train_path, class_name, img_name)\n        os.makedirs(os.path.join(train_path, class_name), exist_ok=True)\n        shutil.move(src, dst)\n\n    for img_name in val_images:\n        src = os.path.join(class_folder_path, img_name)\n        dst = os.path.join(val_path, class_name, img_name)\n        os.makedirs(os.path.join(val_path, class_name), exist_ok=True)\n        shutil.move(src, dst)\n\n    for img_name in test_images:\n        src = os.path.join(class_folder_path, img_name)\n        dst = os.path.join(test_path, class_name, img_name)\n        os.makedirs(os.path.join(test_path, class_name), exist_ok=True)\n        shutil.move(src, dst)","metadata":{"id":"ZLDmCCKjgvf0","outputId":"1965f1d0-2705-4548-b220-fb36a2333df3","execution":{"iopub.status.busy":"2023-07-31T19:55:12.505100Z","iopub.execute_input":"2023-07-31T19:55:12.505430Z","iopub.status.idle":"2023-07-31T19:55:12.514207Z","shell.execute_reply.started":"2023-07-31T19:55:12.505387Z","shell.execute_reply":"2023-07-31T19:55:12.513289Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.Lambda(lambda img: ImageOps.equalize(img, mask=None)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n])\n\ntrain_dataset = ImageFolder(train_path, transform=transform)\nval_dataset = ImageFolder(val_path, transform=transform)\ntest_dataset = ImageFolder(test_path, transform=transform)\n\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=batch_size)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2023-07-31T19:55:12.515902Z","iopub.execute_input":"2023-07-31T19:55:12.516297Z","iopub.status.idle":"2023-07-31T19:55:13.151646Z","shell.execute_reply.started":"2023-07-31T19:55:12.516267Z","shell.execute_reply":"2023-07-31T19:55:13.150634Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"print(len(train_dataset))\nprint(len(test_dataset))\nprint(len(val_dataset))","metadata":{"execution":{"iopub.status.busy":"2023-07-31T19:55:13.153018Z","iopub.execute_input":"2023-07-31T19:55:13.153391Z","iopub.status.idle":"2023-07-31T19:55:13.159270Z","shell.execute_reply.started":"2023-07-31T19:55:13.153341Z","shell.execute_reply":"2023-07-31T19:55:13.158392Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"3659\n785\n784\n","output_type":"stream"}]},{"cell_type":"code","source":"# class CNN(nn.Module):\n#     def __init__(self):\n#         super(CNN, self).__init__()\n#         self.conv_layers = nn.Sequential(\n#             nn.Conv2d(3, 16, kernel_size=3, padding=1),\n#             nn.ReLU(),\n#             nn.MaxPool2d(kernel_size=2, stride=2),\n#             nn.Conv2d(16, 32, kernel_size=3, padding=1),\n#             nn.ReLU(),\n#             nn.MaxPool2d(kernel_size=2, stride=2)\n#         )\n#         self.fc_layers = nn.Sequential(\n#             nn.Linear(32 * 56 * 56, 256),\n#             nn.ReLU(),\n#             nn.Dropout(0.5),\n#             nn.Linear(256, 128),\n#             nn.ReLU(),\n#             nn.Dropout(0.5),\n#             nn.Linear(128, 3)\n#         )\n\n#     def forward(self, x):\n#         x = self.conv_layers(x)\n#         x = x.view(x.size(0), -1)\n#         x = self.fc_layers(x)\n#         return x\n\n\n# class CNN(nn.Module):\n#     def __init__(self):\n#         super(CNN, self).__init__()\n#         self.conv_layers = nn.Sequential(\n#             nn.Conv2d(3, 16, kernel_size=3, padding=1),\n#             nn.ReLU(),\n#             nn.MaxPool2d(kernel_size=2, stride=2),\n#             nn.Conv2d(16, 32, kernel_size=3, padding=1),\n#             nn.ReLU(),\n#             nn.MaxPool2d(kernel_size=2, stride=2),\n#             nn.Conv2d(32, 64, kernel_size=3, padding=1),\n#             nn.ReLU(),\n#             nn.MaxPool2d(kernel_size=2, stride=2),\n#             nn.Conv2d(64, 128, kernel_size=3, padding=1),\n#             nn.ReLU(),\n#             nn.MaxPool2d(kernel_size=2, stride=2),\n#             nn.Conv2d(128, 256, kernel_size=3, padding=1),\n#             nn.ReLU(),\n#             nn.MaxPool2d(kernel_size=2, stride=2),\n#         )\n#         self.fc_layers = nn.Sequential(\n#             nn.Linear(256 * 7 * 7, 512),\n#             nn.ReLU(),\n#             nn.Dropout(0.2),\n#             nn.Linear(512, 1024),\n#             nn.ReLU(),\n#             nn.Dropout(0.2),\n#             nn.Linear(1024, 2048),\n#             nn.ReLU(),\n#             nn.Dropout(0.2),\n#             nn.Linear(2048, 2048),\n#             nn.ReLU(),\n#             nn.Dropout(0.2),\n#             nn.Linear(2048, 2048),\n#             nn.ReLU(),\n#             nn.Dropout(0.2),\n#             nn.Linear(2048, 1024),\n#             nn.ReLU(),\n#             nn.Dropout(0.2),\n#             nn.Linear(1024, 512),\n#             nn.ReLU(),\n#             nn.Dropout(0.2),\n#             nn.Linear(512, 256),\n#             nn.ReLU(),\n#             nn.Dropout(0.2),\n#             nn.Linear(256, 128),\n#             nn.ReLU(),\n#             nn.Dropout(0.2),\n            \n#             nn.Linear(128, 3)\n#         )\n\n#     def forward(self, x):\n#         x = self.conv_layers(x)\n#         x = x.view(x.size(0), -1)\n#         x = self.fc_layers(x)\n#         return x\n\n\n# class CNN(nn.Module):\n#     def __init__(self):\n#         super(CNN, self).__init__()\n#         self.conv_layers = nn.Sequential(\n#             nn.Conv2d(3, 16, kernel_size=3, padding=1),\n#             nn.ReLU(),\n#             nn.MaxPool2d(kernel_size=2, stride=2),\n#             nn.Conv2d(16, 32, kernel_size=3, padding=1),\n#             nn.LeakyReLU(0.1),\n#             nn.Conv2d(32, 64, kernel_size=3, padding=1),\n#             nn.Tanh(),\n#             nn.Conv2d(64, 128, kernel_size=3, padding=1),\n#             nn.Sigmoid(),\n#             nn.MaxPool2d(kernel_size=2, stride=2),\n#             nn.Conv2d(128, 256, kernel_size=3, padding=1),\n#             nn.ReLU(),\n#             nn.Conv2d(256, 512, kernel_size=3, padding=1),\n#             nn.ReLU(),\n#             nn.MaxPool2d(kernel_size=2, stride=2),\n#         )\n#         self.fc_layers = nn.Sequential(\n#             nn.Linear(512 * 28 * 28, 512),\n#             nn.ReLU(),\n#             nn.Dropout(0.5),\n#             nn.Linear(512, 256),\n#             nn.LeakyReLU(0.1),\n#             nn.Dropout(0.5),\n#             nn.Linear(256, 128),\n#             nn.Tanh(),\n#             nn.Dropout(0.5),\n#             nn.Linear(128, 3)\n#         )\n\n#     def forward(self, x):\n#         x = self.conv_layers(x)\n#         x = x.view(x.size(0), -1)\n#         x = self.fc_layers(x)\n#         return x\n\n\n\nclass CNN(nn.Module):\n    def __init__(self):\n        super(CNN, self).__init__()\n        self.conv_layers = nn.Sequential(\n            nn.Conv2d(3, 16, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2)\n        )\n        self.fc_layers = nn.Sequential(\n            nn.Linear(128 * 14 * 14, 512),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(512, 256),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(256, 128),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(128, 3)\n        )\n\n    def forward(self, x):\n        x = self.conv_layers(x)\n        x = x.view(x.size(0), -1)\n        x = self.fc_layers(x)\n        return x\n\n    \nmodel = CNN()","metadata":{"id":"LOd5vY_GMUVs","execution":{"iopub.status.busy":"2023-07-31T19:55:13.162269Z","iopub.execute_input":"2023-07-31T19:55:13.162885Z","iopub.status.idle":"2023-07-31T19:55:13.284571Z","shell.execute_reply.started":"2023-07-31T19:55:13.162849Z","shell.execute_reply":"2023-07-31T19:55:13.283540Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.0001)","metadata":{"id":"hqs6_-Xy0ajp","outputId":"0530b6f0-7a35-463d-aef7-78b2c2dc26ea","execution":{"iopub.status.busy":"2023-07-31T19:55:13.286037Z","iopub.execute_input":"2023-07-31T19:55:13.286498Z","iopub.status.idle":"2023-07-31T19:55:13.294510Z","shell.execute_reply.started":"2023-07-31T19:55:13.286463Z","shell.execute_reply":"2023-07-31T19:55:13.293415Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"patience = 7\nbest_val_loss = float('inf')\ncounter = 0\n\nnum_epochs = num_iters / (len(train_dataset) / batch_size)\nnum_epochs = int(num_epochs)","metadata":{"execution":{"iopub.status.busy":"2023-07-31T19:55:13.296174Z","iopub.execute_input":"2023-07-31T19:55:13.296740Z","iopub.status.idle":"2023-07-31T19:55:13.302982Z","shell.execute_reply.started":"2023-07-31T19:55:13.296708Z","shell.execute_reply":"2023-07-31T19:55:13.301971Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"print(num_epochs)","metadata":{"execution":{"iopub.status.busy":"2023-07-31T19:55:13.304189Z","iopub.execute_input":"2023-07-31T19:55:13.304715Z","iopub.status.idle":"2023-07-31T19:55:13.313389Z","shell.execute_reply.started":"2023-07-31T19:55:13.304682Z","shell.execute_reply":"2023-07-31T19:55:13.312498Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"26\n","output_type":"stream"}]},{"cell_type":"code","source":"model.to(device)\nmodel.train()\n\nfor epoch in range(num_epochs):\n    running_loss = 0.0\n    correct = 0\n    total = 0\n\n    for images, labels in train_loader:\n        images, labels = images.to(device), labels.to(device)\n\n        optimizer.zero_grad()\n\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n\n        _, predicted = outputs.max(1)\n        total += labels.size(0)\n        correct += predicted.eq(labels).sum().item()\n\n    print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {running_loss / len(train_loader):.4f}, '\n          f'Train Accuracy: {100. * correct / total:.2f}%')\n\n    model.eval()\n    val_loss = 0.0\n    val_correct = 0\n    val_total = 0\n\n    with torch.no_grad():\n        for images, labels in val_loader:\n            images, labels = images.to(device), labels.to(device)\n\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            val_loss += loss.item()\n\n            _, predicted = outputs.max(1)\n            val_total += labels.size(0)\n            val_correct += predicted.eq(labels).sum().item()\n\n    print(f'Validation Loss: {val_loss / len(val_loader):.4f}, '\n          f'Validation Accuracy: {100. * val_correct / val_total:.2f}%')\n    \n    if val_loss < best_val_loss:\n        best_val_loss = val_loss\n        counter = 0\n        torch.save(model.state_dict(), 'best_model.pt')\n        print(\"Best Model Save\")\n        model.train()\n        \n    else:\n        counter += 1\n        if counter >= patience:\n            print(f'Early stopping at epoch {epoch + 1}.')\n            break","metadata":{"id":"mZ_oVGjTlimA","execution":{"iopub.status.busy":"2023-07-31T19:55:13.314923Z","iopub.execute_input":"2023-07-31T19:55:13.315264Z","iopub.status.idle":"2023-07-31T20:04:58.651505Z","shell.execute_reply.started":"2023-07-31T19:55:13.315232Z","shell.execute_reply":"2023-07-31T20:04:58.650420Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"Epoch 1/26, Loss: 0.6207, Train Accuracy: 72.72%\nValidation Loss: 0.4189, Validation Accuracy: 83.04%\nBest Model Save\nEpoch 2/26, Loss: 0.3050, Train Accuracy: 88.25%\nValidation Loss: 0.2627, Validation Accuracy: 89.80%\nBest Model Save\nEpoch 3/26, Loss: 0.2253, Train Accuracy: 91.25%\nValidation Loss: 0.2244, Validation Accuracy: 92.22%\nBest Model Save\nEpoch 4/26, Loss: 0.1996, Train Accuracy: 92.95%\nValidation Loss: 0.1905, Validation Accuracy: 92.98%\nBest Model Save\nEpoch 5/26, Loss: 0.1626, Train Accuracy: 94.01%\nValidation Loss: 0.1652, Validation Accuracy: 94.77%\nBest Model Save\nEpoch 6/26, Loss: 0.1451, Train Accuracy: 94.51%\nValidation Loss: 0.1474, Validation Accuracy: 95.03%\nBest Model Save\nEpoch 7/26, Loss: 0.1243, Train Accuracy: 95.55%\nValidation Loss: 0.1567, Validation Accuracy: 94.52%\nEpoch 8/26, Loss: 0.1024, Train Accuracy: 96.17%\nValidation Loss: 0.1412, Validation Accuracy: 95.54%\nBest Model Save\nEpoch 9/26, Loss: 0.1055, Train Accuracy: 96.58%\nValidation Loss: 0.1396, Validation Accuracy: 95.79%\nBest Model Save\nEpoch 10/26, Loss: 0.0878, Train Accuracy: 97.02%\nValidation Loss: 0.1333, Validation Accuracy: 95.66%\nBest Model Save\nEpoch 11/26, Loss: 0.0794, Train Accuracy: 96.72%\nValidation Loss: 0.1325, Validation Accuracy: 96.05%\nBest Model Save\nEpoch 12/26, Loss: 0.0668, Train Accuracy: 97.57%\nValidation Loss: 0.1398, Validation Accuracy: 96.05%\nEpoch 13/26, Loss: 0.0491, Train Accuracy: 98.25%\nValidation Loss: 0.1643, Validation Accuracy: 95.28%\nEpoch 14/26, Loss: 0.0433, Train Accuracy: 98.61%\nValidation Loss: 0.1318, Validation Accuracy: 96.05%\nBest Model Save\nEpoch 15/26, Loss: 0.0496, Train Accuracy: 98.36%\nValidation Loss: 0.1293, Validation Accuracy: 96.56%\nBest Model Save\nEpoch 16/26, Loss: 0.0466, Train Accuracy: 98.55%\nValidation Loss: 0.1314, Validation Accuracy: 96.68%\nEpoch 17/26, Loss: 0.0268, Train Accuracy: 98.99%\nValidation Loss: 0.1768, Validation Accuracy: 95.79%\nEpoch 18/26, Loss: 0.0283, Train Accuracy: 99.10%\nValidation Loss: 0.1271, Validation Accuracy: 96.30%\nBest Model Save\nEpoch 19/26, Loss: 0.0185, Train Accuracy: 99.45%\nValidation Loss: 0.1692, Validation Accuracy: 96.05%\nEpoch 20/26, Loss: 0.0173, Train Accuracy: 99.45%\nValidation Loss: 0.1710, Validation Accuracy: 96.17%\nEpoch 21/26, Loss: 0.0191, Train Accuracy: 99.32%\nValidation Loss: 0.1544, Validation Accuracy: 96.30%\nEpoch 22/26, Loss: 0.0157, Train Accuracy: 99.40%\nValidation Loss: 0.1649, Validation Accuracy: 96.30%\nEpoch 23/26, Loss: 0.0078, Train Accuracy: 99.84%\nValidation Loss: 0.1787, Validation Accuracy: 96.43%\nEpoch 24/26, Loss: 0.0050, Train Accuracy: 99.86%\nValidation Loss: 0.1835, Validation Accuracy: 96.68%\nEpoch 25/26, Loss: 0.0057, Train Accuracy: 99.84%\nValidation Loss: 0.1680, Validation Accuracy: 96.56%\nEarly stopping at epoch 25.\n","output_type":"stream"}]},{"cell_type":"code","source":"model = CNN().to(device)\nmodel.load_state_dict(torch.load('best_model.pt'))\nprint(\"Best Model Loaded\")\nmodel.eval()\ntest_correct = 0\ntest_total = 0\n\nwith torch.no_grad():\n    for images, labels in test_loader:\n        images, labels = images.to(device), labels.to(device)\n\n        outputs = model(images)\n        _, predicted = outputs.max(1)\n        test_total += labels.size(0)\n        test_correct += predicted.eq(labels).sum().item()\n\ntest_accuracy = 100. * test_correct / test_total\nprint(f'Test Accuracy: {test_accuracy:.2f}%')","metadata":{"execution":{"iopub.status.busy":"2023-07-31T20:04:58.653004Z","iopub.execute_input":"2023-07-31T20:04:58.653350Z","iopub.status.idle":"2023-07-31T20:05:02.562429Z","shell.execute_reply.started":"2023-07-31T20:04:58.653305Z","shell.execute_reply":"2023-07-31T20:05:02.561438Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"Best Model Loaded\nTest Accuracy: 96.94%\n","output_type":"stream"}]}]}